{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import ijson\n",
    "import itertools\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import urllib.request\n",
    "from collections import OrderedDict\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import html\n",
    "from pandas.io.json import json_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.getenv(\"DATA_DIR\")\n",
    "content_api = os.path.join(DATA_DIR, \"content_api\")\n",
    "content_file = os.path.join(content_api,\"content.json.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(url):\n",
    "    links = []\n",
    "    try:\n",
    "        soup = BeautifulSoup(url, \"html5lib\")\n",
    "        links = [link.get('href') for link in soup.findAll('a', href=True)]\n",
    "    except Exception:\n",
    "        print(\"error\")\n",
    "    return [l for l in links if l.startswith(\"/\")]\n",
    "\n",
    "\n",
    "look = ['title', 'body']\n",
    "child_keys = ['title', 'description']\n",
    "filtered = ['body', 'brand', 'documents', 'final_outcome_detail', 'final_outcome_documents',\n",
    "            'government', 'headers', 'introduction', 'introductory_paragraph',\n",
    "            'licence_overview', 'licence_short_description', 'logo', 'metadata', 'more_information', 'need_to_know',\n",
    "            'other_ways_to_apply', 'summary', 'ways_to_respond', 'what_you_need_to_know', 'will_continue_on', 'parts',\n",
    "            'collection_groups']\n",
    "\n",
    "\n",
    "def is_html(raw_text):\n",
    "    return html.fromstring(str(raw_text)).find('.//*') is not None\n",
    "\n",
    "\n",
    "def is_json(raw_text):\n",
    "    try:\n",
    "        json_normalize(raw_text).columns.tolist()\n",
    "    except AttributeError:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def get_text(x):\n",
    "    links = []\n",
    "    string_json = json.dumps(OrderedDict(x))\n",
    "    order_json = json.loads(string_json, object_pairs_hook=OrderedDict)\n",
    "    for key, raw_text in sorted(order_json.items()):\n",
    "        if key in filtered:\n",
    "            if isinstance(raw_text, str) and len(raw_text) > 1:\n",
    "                links.extend(get_links(raw_text))\n",
    "            elif isinstance(raw_text, list) and len(raw_text) > 0:\n",
    "                for sub_text in raw_text:\n",
    "                    if is_json(sub_text):\n",
    "                        links.extend(nested_extract(sub_text))\n",
    "                    elif is_html(sub_text):\n",
    "                        links.extend(get_links(sub_text))\n",
    "    return list(set(links))\n",
    "\n",
    "\n",
    "def nested_extract(x):\n",
    "    links = []\n",
    "    string_json2 = json.dumps(OrderedDict(x))\n",
    "    order_json2 = json.loads(string_json2, object_pairs_hook=OrderedDict)\n",
    "    if ('body' or 'title') in order_json2.keys():\n",
    "        for item in look:\n",
    "            links.extend(get_links(order_json2[item]))\n",
    "    elif 'child_sections' in order_json2.keys():\n",
    "        for child in order_json2['child_sections']:\n",
    "            for key in child_keys:\n",
    "                links.extend(get_links(key))\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_link_types(content_item):\n",
    "    links = []\n",
    "    related_links = []\n",
    "    coll_links = []\n",
    "    \n",
    "    if content_item is not None:\n",
    "        links = get_text(content_item['details'])\n",
    "        related_links = []\n",
    "        coll_links = []\n",
    "        if 'ordered_related_items' in content_item['links'].keys():\n",
    "            related_links = [related_item['base_path'] for related_item in\n",
    "                             content_item['links']['ordered_related_items'] if\n",
    "                             'base_path' in related_item.keys()]\n",
    "\n",
    "        if 'documents' in content_item['links'].keys():\n",
    "            coll_links = [document['base_path'] for document in content_item['links']['documents'] if\n",
    "                          'base_path' in document.keys()]\n",
    "        \n",
    "    return links, related_links, coll_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 21:24:42\n",
      "i: 0 21:24:42\n",
      "i: 10000 21:27:03\n",
      "i: 20000 21:29:19\n",
      "i: 30000 21:31:35\n",
      "i: 40000 21:33:57\n",
      "i: 50000 21:36:16\n",
      "i: 60000 21:38:34\n"
     ]
    }
   ],
   "source": [
    "destination = os.path.join(content_api, \"content_reduced.json.gz\")\n",
    "print(\"Start:\",datetime.datetime.now().strftime(\"%H:%M:%S\"))\n",
    "with gzip.open(content_file, \"rt\") as reader, gzip.open(destination, 'wb') as writer:\n",
    "    content_generator = ijson.items(reader, prefix='item')\n",
    "    for i,content_item in enumerate(itertools.islice(content_generator, 0, None)):\n",
    "        row = {}\n",
    "        row['base_path'] = content_item['base_path']\n",
    "        row['content_id'] = content_item['content_id']\n",
    "        row['title'] = content_item['title']\n",
    "        row['description'] = content_item['description']\n",
    "        row['details'] = content_item['details']\n",
    "        l1, l2, l3 = extract_link_types(content_item)\n",
    "        row['embdedded_links'] = l1\n",
    "        row['related_links'] = l2\n",
    "        row['coll_links'] = l3\n",
    "        string_dict = json.dumps(row)\n",
    "#         row_list.append(string_dict)\n",
    "        writer.write(\"{}\\n\".format(string_dict).encode())\n",
    "        if i % 10000 == 0:\n",
    "            print(\"i:\",i,datetime.datetime.now().strftime(\"%H:%M:%S\"))\n",
    "print(\"End:\",datetime.datetime.now().strftime(\"%H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_list = []\n",
    "with gzip.open(destination, 'rt') as reader:\n",
    "    for line in reader.readlines():\n",
    "        row_list.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame([json.loads(s) for s in row_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(destination, compression=\"gzip\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
